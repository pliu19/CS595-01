{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The data is IMDB - review dataset. It's available from the website \"http://ai.stanford.edu/~amaas/data/sentiment/\". \n",
    "\n",
    "The review is binary case which could be positive/negative review. It provides 25,000 reviews for training, and 25,000 reviews for testing. The distribution of class in training and testing is balanced, which means it has 12500 positive reviews and 12500 negative reviews in both training and testing.\n",
    "\n",
    "In this assignment, we will use countvectorizer which means each token feature will be binary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_imdb(path):\n",
    "\n",
    "    print(\"Loading the imdb reviews data\")\n",
    "\n",
    "    train_neg_files = glob.glob(path+\"/train/neg/*.txt\")\n",
    "    train_pos_files = glob.glob(path+\"/train/pos/*.txt\")\n",
    "\n",
    "    train_corpus = []\n",
    "    y_train = []\n",
    "    \n",
    "    for tnf in train_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        train_corpus.append(line)\n",
    "        y_train.append(0)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    for tpf in train_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        line = f.read()\n",
    "        train_corpus.append(line)\n",
    "        y_train.append(1)\n",
    "        f.close()\n",
    "    \n",
    "    print(\"Training Data loaded.\")\n",
    "    print()\n",
    "    \n",
    "    test_neg_files = glob.glob(path+\"/test/neg/*.txt\")\n",
    "    test_pos_files = glob.glob(path+\"/test/pos/*.txt\")\n",
    "\n",
    "    test_corpus = []\n",
    "\n",
    "    y_test = []\n",
    "\n",
    "    for tnf in test_neg_files:\n",
    "        f = open(tnf, 'r', encoding=\"utf8\")\n",
    "        test_corpus.append(f.read())\n",
    "        y_test.append(0)\n",
    "        f.close()\n",
    "\n",
    "    for tpf in test_pos_files:\n",
    "        f = open(tpf, 'r', encoding=\"utf8\")\n",
    "        test_corpus.append(f.read())\n",
    "        y_test.append(1)\n",
    "        f.close()\n",
    "\n",
    "    print(\"Testing Data loaded.\")\n",
    "    print()\n",
    "    \n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test)\n",
    "\n",
    "    return train_corpus, test_corpus, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imdb_path = \"../aclImdb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the imdb reviews data\n",
      "Training Data loaded.\n",
      "\n",
      "Testing Data loaded.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_corpus, test_corpus, y_train, y_test = load_imdb(imdb_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarize and vectorize the data into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=5, max_df=1.0, binary=True)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_corpus)\n",
    "\n",
    "X_test = vectorizer.transform(test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 27272)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82904"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_predict = clf.predict(X_test)\n",
    "y_proba = clf.predict_proba(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Analysis of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_bias(clf):\n",
    "    return clf.class_log_prior_[1] - clf.class_log_prior_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It should be zero since the data is balanced as 50% vs 50%\n",
    "\n",
    "get_bias(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In this case, we only need to calculate the evidence (negative and positive) for all the features \n",
    "\n",
    "def evidences(clf, X):\n",
    "    \n",
    "    X = X.todense()\n",
    "    \n",
    "    X_presence = X.copy()\n",
    "    \n",
    "    X_absence = 1 - X\n",
    "        \n",
    "    absence_log_prob_ = np.log(1 - np.exp(clf.feature_log_prob_))\n",
    "    \n",
    "    presence_log_ratios = clf.feature_log_prob_[1] - clf.feature_log_prob_[0]\n",
    "    \n",
    "    absence_log_ratios = absence_log_prob_[1] - absence_log_prob_[0]\n",
    "    \n",
    "    presence_neg_log_ratios = presence_log_ratios * (presence_log_ratios<0)\n",
    "    presence_pos_log_ratios = presence_log_ratios * (presence_log_ratios>0)\n",
    "    \n",
    "    absence_neg_log_ratios = absence_log_ratios * (absence_log_ratios<0)\n",
    "    absence_pos_log_ratios = absence_log_ratios * (absence_log_ratios>0)\n",
    "    \n",
    "    p_neg_evi = np.dot(X_presence, presence_neg_log_ratios)\n",
    "    p_pos_evi = np.dot(X_presence, presence_pos_log_ratios)\n",
    "    \n",
    "    a_neg_evi = np.dot(X_absence, absence_neg_log_ratios)\n",
    "    a_pos_evi = np.dot(X_absence, absence_pos_log_ratios)\n",
    "    \n",
    "    return p_neg_evi.item(0), p_pos_evi.item(0), a_neg_evi.item(0), a_pos_evi.item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pos_neg_evidence(clf, x_vector):\n",
    "    \n",
    "    p_neg_evi, p_pos_evi, a_neg_evi, a_pos_evi = evidences(clf, x_vector)\n",
    "    \n",
    "    return p_neg_evi + a_neg_evi, p_pos_evi + a_pos_evi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "evidence = []\n",
    "\n",
    "for i in X_test:\n",
    "    evidence.append(pos_neg_evidence(clf, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence = np.asarray(evidence)\n",
    "\n",
    "evidence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-36.61238513,  30.5457996 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evidence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neg_evidence = evidence[:, 0]\n",
    "pos_evidence = evidence[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a) the total positive log-evidence \n",
    "# b) the total negative log-evidence\n",
    "# c) probability distribution\n",
    "# d) top 3 features values that contribute most to the positive evidence\n",
    "# e) top 3 feature values that contribute the most to the negative evidence. \n",
    "# Print this information on the following object types\n",
    "\n",
    "\n",
    "def print_infor(X_vector, index, evidence, proba, clf, vec):\n",
    "    \n",
    "    neg_evi = evidence[:, 0]\n",
    "    pos_evi = evidence[:, 1]\n",
    "    \n",
    "    print(\"The total positive log-evidence: %s\" %str(pos_evi[index]))\n",
    "    print(\"The total negative log-evidence: %s\" %str(neg_evi[index]))\n",
    "           \n",
    "    print(\"The probability distribution: %s\" %str(proba[index]))\n",
    "    \n",
    "    top_features(X_vector, clf, vec)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_features(X_vector, clf, vec):\n",
    "    \n",
    "    X_vector = X_vector.todense()\n",
    "    \n",
    "    X_presence = X_vector.copy()\n",
    "    \n",
    "    X_absence = 1 - X_vector\n",
    "        \n",
    "    # p(x=absence|y) = 1 - p(x=presence|y)    \n",
    "    # ln[p(x=absence|y)] = ln[1 - e^ln[p=presence|y]]\n",
    "    absence_log_prob_ = np.log(1 - np.exp(clf.feature_log_prob_))\n",
    "    \n",
    "    # log-ratio => ln[p(x=presence|y=true)/p(x=absence|y=false)] = ln[p(x=presence|y=true)] - ln[p(x=absence|y=true)]\n",
    "    presence_log_ratios = clf.feature_log_prob_[1] - clf.feature_log_prob_[0]\n",
    "    \n",
    "    # log-ratio => ln[p(x=absense|y=true)/p(x=presence|y=false)] = ln[p(x=absense|y=true)] - ln[p(x=presence|y=true)]\n",
    "    absence_log_ratios = absence_log_prob_[1] - absence_log_prob_[0]\n",
    "    \n",
    "    presence_neg_log_ratios = presence_log_ratios * (presence_log_ratios<0)\n",
    "    presence_pos_log_ratios = presence_log_ratios * (presence_log_ratios>0)\n",
    "    \n",
    "    absence_neg_log_ratios = absence_log_ratios * (absence_log_ratios<0)\n",
    "    absence_pos_log_ratios = absence_log_ratios * (absence_log_ratios>0)\n",
    "    \n",
    "    p_neg_evi = np.multiply(X_presence, presence_neg_log_ratios)\n",
    "    p_pos_evi = np.multiply(X_presence, presence_pos_log_ratios)\n",
    "    \n",
    "    a_neg_evi = np.multiply(X_absence, absence_neg_log_ratios)\n",
    "    a_pos_evi = np.multiply(X_absence, absence_pos_log_ratios)\n",
    "    \n",
    "    positive = np.add(p_pos_evi, a_pos_evi).A1\n",
    "    negative = np.add(p_neg_evi, a_neg_evi).A1\n",
    "    \n",
    "    total = np.add(positive, negative)\n",
    "        \n",
    "    features_name = vec.get_feature_names()\n",
    "    \n",
    "    top_positive_idx = np.argsort(positive)[::-1][:3]\n",
    "    print(\"\")\n",
    "    print(\"Top 3 features values that contribute the most to the positive evidence\")\n",
    "       \n",
    "    for idx in top_positive_idx:\n",
    "        \n",
    "        print(\"Feature name: %s \\t\\t value: %s \\t\\t Evidence: %s\" %(features_name[idx], str(X_vector.A1[idx]), str(positive[idx])))\n",
    "        \n",
    "    top_negative_idx = np.argsort(negative)[:3]\n",
    "    print(\"\")\n",
    "    print(\"Top 3 features values that contribute the most to the negative evidence\")\n",
    "    for idx in top_negative_idx:\n",
    "        print(\"Feature name: %s \\t\\t value: %s \\t\\t Evidence: %s\" %(features_name[idx], str(X_vector.A1[idx]), str(negative[idx])))\n",
    "            \n",
    "#     print(np.count_nonzero(p_pos_evi))\n",
    "#     print(np.count_nonzero(a_pos_evi))\n",
    "#     print(np.count_nonzero(positive))\n",
    "    \n",
    "    return None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. The most positive object with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(y_proba[:,1])\n",
    "\n",
    "idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total positive log-evidence: 126.092040458\n",
      "The total negative log-evidence: -64.9802025856\n",
      "The probability distribution: [  2.88048775e-27   1.00000000e+00]\n",
      "\n",
      "Top 3 features values that contribute the most to the positive evidence\n",
      "Feature name: pinjar \t\t value: 1 \t\t Evidence: 2.19722457734\n",
      "Feature name: maintained \t\t value: 1 \t\t Evidence: 1.68639895357\n",
      "Feature name: sadness \t\t value: 1 \t\t Evidence: 1.6635051337\n",
      "\n",
      "Top 3 features values that contribute the most to the negative evidence\n",
      "Feature name: existent \t\t value: 1 \t\t Evidence: -1.99720344344\n",
      "Feature name: adage \t\t value: 1 \t\t Evidence: -1.94591014906\n",
      "Feature name: bearings \t\t value: 1 \t\t Evidence: -1.79175946923\n"
     ]
    }
   ],
   "source": [
    "print_infor(X_test[idx], idx, evidence, y_proba, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The most negative object with respect to the probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10505"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmin(y_proba[:,1])\n",
    "\n",
    "idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total positive log-evidence: 48.0671904571\n",
      "The total negative log-evidence: -137.652105367\n",
      "The probability distribution: [  1.00000000e+00   1.24098289e-39]\n",
      "\n",
      "Top 3 features values that contribute the most to the positive evidence\n",
      "Feature name: sloth \t\t value: 1 \t\t Evidence: 1.38629436112\n",
      "Feature name: ferocious \t\t value: 1 \t\t Evidence: 1.20397280433\n",
      "Feature name: joy \t\t value: 1 \t\t Evidence: 0.962571484438\n",
      "\n",
      "Top 3 features values that contribute the most to the negative evidence\n",
      "Feature name: manos \t\t value: 1 \t\t Evidence: -3.33220451018\n",
      "Feature name: unwatchable \t\t value: 1 \t\t Evidence: -2.9856819377\n",
      "Feature name: waster \t\t value: 1 \t\t Evidence: -2.63905732962\n"
     ]
    }
   ],
   "source": [
    "print_infor(X_test[idx], idx, evidence, y_proba, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. The object that has the largest positive evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-163.3492882   194.84244513]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmax(pos_evidence)\n",
    "\n",
    "print(evidence[idx])\n",
    "\n",
    "idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total positive log-evidence: 194.842445129\n",
      "The total negative log-evidence: -163.349288197\n",
      "The probability distribution: [  2.10230502e-14   1.00000000e+00]\n",
      "\n",
      "Top 3 features values that contribute the most to the positive evidence\n",
      "Feature name: quibble \t\t value: 1 \t\t Evidence: 3.04452243772\n",
      "Feature name: genesis \t\t value: 1 \t\t Evidence: 2.07944154168\n",
      "Feature name: beckett \t\t value: 1 \t\t Evidence: 2.07944154168\n",
      "\n",
      "Top 3 features values that contribute the most to the negative evidence\n",
      "Feature name: clowns \t\t value: 1 \t\t Evidence: -2.63905732962\n",
      "Feature name: lamest \t\t value: 1 \t\t Evidence: -2.25129179861\n",
      "Feature name: worst \t\t value: 1 \t\t Evidence: -2.19282896586\n"
     ]
    }
   ],
   "source": [
    "print_infor(X_test[idx], idx, evidence, y_proba, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. The object that has the largest (in magnitude) negative evidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-163.3492882   194.84244513]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18112"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.argmin(neg_evidence)\n",
    "\n",
    "print(evidence[idx])\n",
    "\n",
    "idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total positive log-evidence: 194.842445129\n",
      "The total negative log-evidence: -163.349288197\n",
      "The probability distribution: [  2.10230502e-14   1.00000000e+00]\n",
      "\n",
      "Top 3 features values that contribute the most to the positive evidence\n",
      "Feature name: quibble \t\t value: 1 \t\t Evidence: 3.04452243772\n",
      "Feature name: genesis \t\t value: 1 \t\t Evidence: 2.07944154168\n",
      "Feature name: beckett \t\t value: 1 \t\t Evidence: 2.07944154168\n",
      "\n",
      "Top 3 features values that contribute the most to the negative evidence\n",
      "Feature name: clowns \t\t value: 1 \t\t Evidence: -2.63905732962\n",
      "Feature name: lamest \t\t value: 1 \t\t Evidence: -2.25129179861\n",
      "Feature name: worst \t\t value: 1 \t\t Evidence: -2.19282896586\n"
     ]
    }
   ],
   "source": [
    "print_infor(X_test[idx], idx, evidence, y_proba, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. The most uncertain object (the probabilities are closest to 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-33.01112016  33.01051477]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15608"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncerts = np.min(y_proba, axis=1)\n",
    "\n",
    "idx = np.argmax(uncerts)\n",
    "\n",
    "print(evidence[idx])\n",
    "\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total positive log-evidence: 33.0105147676\n",
      "The total negative log-evidence: -33.0111201556\n",
      "The probability distribution: [ 0.50015135  0.49984865]\n",
      "\n",
      "Top 3 features values that contribute the most to the positive evidence\n",
      "Feature name: donovan \t\t value: 1 \t\t Evidence: 1.29928298413\n",
      "Feature name: joy \t\t value: 1 \t\t Evidence: 0.962571484438\n",
      "Feature name: carol \t\t value: 1 \t\t Evidence: 0.826678573184\n",
      "\n",
      "Top 3 features values that contribute the most to the negative evidence\n",
      "Feature name: poor \t\t value: 1 \t\t Evidence: -1.20207912055\n",
      "Feature name: cow \t\t value: 1 \t\t Evidence: -0.944461608841\n",
      "Feature name: slammer \t\t value: 1 \t\t Evidence: -0.916290731874\n"
     ]
    }
   ],
   "source": [
    "print_infor(X_test[idx], idx, evidence, y_proba, clf, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
